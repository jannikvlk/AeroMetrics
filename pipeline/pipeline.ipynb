{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import importlib\n",
    "\n",
    "from files import *\n",
    "\n",
    "import json\n",
    "import numbers\n",
    "from actions import (\n",
    "    remove_typos,\n",
    "    CalculateWeightAndTrimAction,\n",
    "    CheckinMsgProcessor,\n",
    "    CreateLoadingInstructionAction,\n",
    "    CreateLoadsheetAction,\n",
    "    CreateZFWMessageAction,\n",
    "    EstimateStorePaxDataAction,\n",
    "    RampFinalAction,\n",
    "    SendFuelOrderAction,\n",
    "    SendLoadingInstructionAction,\n",
    "    SendLoadsheetAction,\n",
    "    SetActualBagWeightIndicatorAction,\n",
    "    SetCKIPaxDistributionAction,\n",
    "    StoreAircraftDataAction,\n",
    "    StorePaxDataAction,\n",
    "    StorePaxDataGuiAction,\n",
    "    StoreRegistrationAndConfigurationAc,\n",
    "    TdmCreateLoadingInstructionAction,\n",
    "    TransferCargoAction,\n",
    "    TransferCheckinDataAction,\n",
    "    UpdateEstimatesAction,\n",
    "    UpdateFuelDataAction,\n",
    "    UpdateLoadTableAction,\n",
    "    UpdateTransitLoadTableAction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process:\n",
    "    def __init__(self, func: Callable, **kwargs):\n",
    "        self.func = func\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_func(self) -> Callable:\n",
    "        return self.func\n",
    "\n",
    "    def get_kwargs(self):\n",
    "        return self.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess(processes: List[Process], workers: int):\n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        futures = []\n",
    "        for process in processes:\n",
    "            futures.append(executor.submit(process.get_func(), **process.get_kwargs())),\n",
    "\n",
    "        for future in futures:\n",
    "            future.result()  # This will re-raise any exceptions that occurred during task execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix broken CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_broken_csv(csv_input_file, csv_output_file):\n",
    "    id_timestamp_pattern = re.compile(r\"^\\d+,\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\")\n",
    "\n",
    "    with open(csv_input_file, \"r\", encoding=\"utf-8\") as infile, open(\n",
    "        csv_output_file, \"w\", encoding=\"utf-8\", newline=\"\"\n",
    "    ) as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        buffer = []\n",
    "        first_line = True\n",
    "\n",
    "        # Read the header from the input file and write it to the output file\n",
    "        header = next(reader)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for line in infile:\n",
    "            line = line.rstrip(\"\\n\")  # Retain trailing newlines by using rstrip('\\n')\n",
    "\n",
    "            # Check if the line matches the pattern for a new entry\n",
    "            if id_timestamp_pattern.match(line):\n",
    "                # If buffer is not empty, process the previous buffered entry\n",
    "                if not first_line:\n",
    "                    combined_line = \"\\n\".join(buffer)\n",
    "                    # Add closing quote if the previous entry was not closed properly\n",
    "                    if combined_line.count('\"') % 2 != 0:\n",
    "                        combined_line += '\"'\n",
    "                    writer.writerow(csv.reader([combined_line]).__next__())\n",
    "\n",
    "                # Start a new buffer with the current line\n",
    "                buffer = [line]\n",
    "                first_line = False\n",
    "            else:\n",
    "                # Continue the buffer\n",
    "                buffer.append(line)\n",
    "\n",
    "        # Handle the last buffer if not empty\n",
    "        if buffer:\n",
    "            combined_line = \"\\n\".join(buffer)\n",
    "            # Add closing quote if the last entry was not closed properly\n",
    "            if combined_line.count('\"') % 2 != 0:\n",
    "                combined_line += '\"'\n",
    "            writer.writerow(csv.reader([combined_line]).__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_AB,\n",
    "            csv_output_file=CSV_AB_FIXED,\n",
    "        ),\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_MN,\n",
    "            csv_output_file=CSV_MN_FIXED,\n",
    "        ),\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_ZY,\n",
    "            csv_output_file=CSV_ZY_FIXED,\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV files and convert them to Parquet files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet_cleaning(csv_file: Path, parquet_file: Path) -> pd.DataFrame:\n",
    "\n",
    "    # read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # remove leading and trailing linebreaks and whitespaces\n",
    "    def custom_strip(text):\n",
    "        if isinstance(text, str):\n",
    "            return text.strip(\"\\n\\r\").strip()\n",
    "        return text\n",
    "\n",
    "    df = df.map(custom_strip, na_action=\"ignore\")\n",
    "\n",
    "    # Drop duplicates ignoring the index\n",
    "    df.drop_duplicates(subset=list(df.columns).remove(\"id\"), inplace=True)\n",
    "\n",
    "    # Set the unique identifier for every flight\n",
    "    df[\"flightid\"] = df.apply(\n",
    "        lambda x: f\"{x['airline_code']}_{x['flight_number']}_{x['flight_date']}_{x['departure_airport']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Convert creation_time to a datetime object\n",
    "    df[\"creation_time\"] = pd.to_datetime(df[\"creation_time\"])\n",
    "\n",
    "    # Write the dataframe to parquet\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_AB_FIXED, parquet_file=PARQUET_AB\n",
    "        ),\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_MN_FIXED, parquet_file=PARQUET_MN\n",
    "        ),\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_ZY_FIXED, parquet_file=PARQUET_ZY\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Action Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(remove_typos)\n",
    "importlib.reload(CalculateWeightAndTrimAction)\n",
    "importlib.reload(CheckinMsgProcessor)\n",
    "importlib.reload(CreateLoadingInstructionAction)\n",
    "importlib.reload(CreateLoadsheetAction)\n",
    "importlib.reload(CreateZFWMessageAction)\n",
    "importlib.reload(EstimateStorePaxDataAction)\n",
    "importlib.reload(RampFinalAction)\n",
    "importlib.reload(SendFuelOrderAction)\n",
    "importlib.reload(SendLoadingInstructionAction)\n",
    "importlib.reload(SendLoadsheetAction)\n",
    "importlib.reload(SetActualBagWeightIndicatorAction)\n",
    "importlib.reload(SetCKIPaxDistributionAction)\n",
    "importlib.reload(StoreAircraftDataAction)\n",
    "importlib.reload(StorePaxDataAction)\n",
    "importlib.reload(StorePaxDataGuiAction)\n",
    "importlib.reload(StoreRegistrationAndConfigurationAc)\n",
    "importlib.reload(TdmCreateLoadingInstructionAction)\n",
    "importlib.reload(TransferCargoAction)\n",
    "importlib.reload(TransferCheckinDataAction)\n",
    "importlib.reload(UpdateEstimatesAction)\n",
    "importlib.reload(UpdateFuelDataAction)\n",
    "importlib.reload(UpdateLoadTableAction)\n",
    "importlib.reload(UpdateTransitLoadTableAction)\n",
    "\n",
    "action_extractors = {\n",
    "    \"CalculateWeightAndTrimAction\": CalculateWeightAndTrimAction.extract,\n",
    "    \"CheckinMsgProcessor\": CheckinMsgProcessor.extract,\n",
    "    \"CreateLoadingInstructionAction\": CreateLoadingInstructionAction.extract,\n",
    "    \"CreateLoadsheetAction\": CreateLoadsheetAction.extract,\n",
    "    \"CreateZFWMessageAction\": CreateZFWMessageAction.extract,\n",
    "    \"EstimateStorePaxDataAction\": EstimateStorePaxDataAction.extract,\n",
    "    \"RampFinalAction\": RampFinalAction.extract,\n",
    "    \"SendFuelOrderAction\": SendFuelOrderAction.extract,\n",
    "    \"SendLoadingInstructionAction\": SendLoadingInstructionAction.extract,\n",
    "    \"SendLoadsheetAction\": SendLoadsheetAction.extract,\n",
    "    \"SetActualBagWeightIndicatorAction\": SetActualBagWeightIndicatorAction.extract,\n",
    "    \"SetCKIPaxDistributionAction\": SetCKIPaxDistributionAction.extract,\n",
    "    \"StoreAircraftDataAction\": StoreAircraftDataAction.extract,\n",
    "    \"StorePaxDataAction\": StorePaxDataAction.extract,\n",
    "    \"StorePaxDataGuiAction\": StorePaxDataGuiAction.extract,\n",
    "    \"StoreRegistrationAndConfigurationAc\": StoreRegistrationAndConfigurationAc.extract,\n",
    "    \"TdmCreateLoadingInstructionAction\": TdmCreateLoadingInstructionAction.extract,\n",
    "    \"TransferCargoAction\": TransferCargoAction.extract,\n",
    "    \"TransferCheckinDataAction\": TransferCheckinDataAction.extract,\n",
    "    \"UpdateEstimatesAction\": UpdateEstimatesAction.extract,\n",
    "    \"UpdateFuelDataAction\": UpdateFuelDataAction.extract,\n",
    "    \"UpdateLoadTableAction\": UpdateLoadTableAction.extract,\n",
    "    \"UpdateTransitLoadTableAction\": UpdateTransitLoadTableAction.extract,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_data(\n",
    "    source_file: Path,\n",
    "    target_file: Path,\n",
    "    label: str | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extract specific data based on predefined action extractors, optionally displaying a progress bar and labels.\n",
    "\n",
    "    This function iterates over a dictionary of action names and their associated extractor functions, applying each\n",
    "    extractor to the relevant entries in the DataFrame. The results are stored in new columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which data will be extracted.\n",
    "            It must contain columns that match the keys in the action_extractors dictionary.\n",
    "        progress_bar (bool, optional): If True, displays a progress bar during the data extraction process.\n",
    "            Useful for visual feedback during long operations. Defaults to False.\n",
    "        label (str | None, optional): An optional label that prefixes the print statements for better traceability during debugging.\n",
    "            If None, only the action name is printed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns containing the extracted data.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        df = pd.read_parquet(source_file)\n",
    "\n",
    "    for action_name, extractor in action_extractors.items():\n",
    "        if extractor is not None:\n",
    "            if len(df[df.action_name == action_name]) == 0:\n",
    "                print(label, action_name, \"not found in DataFrame\")\n",
    "                continue\n",
    "\n",
    "            if label:\n",
    "                print(label, action_name)\n",
    "            else:\n",
    "                print(action_name)\n",
    "\n",
    "            df[f\"data_{action_name}\"] = df[df.action_name == action_name][\n",
    "                \"entry_details\"\n",
    "            ].apply(extractor)\n",
    "\n",
    "    df.to_parquet(target_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZYXW CalculateWeightAndTrimAction\n",
      "ABCD CalculateWeightAndTrimAction\n",
      "MNOP CalculateWeightAndTrimAction\n",
      "ZYXW CheckinMsgProcessor\n",
      "ZYXW CreateLoadingInstructionAction\n",
      "ZYXW CreateLoadsheetAction\n",
      "ZYXW CreateZFWMessageAction\n",
      "ZYXW EstimateStorePaxDataAction\n",
      "ZYXW RampFinalAction\n",
      "ZYXW SendFuelOrderAction\n",
      "ZYXW SendLoadingInstructionAction\n",
      "ZYXW SendLoadsheetAction\n",
      "ZYXW SetActualBagWeightIndicatorAction\n",
      "ZYXW SetCKIPaxDistributionAction\n",
      "ZYXW StoreAircraftDataAction\n",
      "ZYXW StorePaxDataAction\n",
      "ABCD CheckinMsgProcessor\n",
      "ZYXW StorePaxDataGuiAction\n",
      "ZYXW StoreRegistrationAndConfigurationAc\n",
      "ZYXW TdmCreateLoadingInstructionAction\n",
      "ZYXW TransferCargoAction\n",
      "ABCD CreateLoadingInstructionAction\n",
      "ABCD CreateLoadsheetAction\n",
      "ZYXW TransferCheckinDataAction not found in DataFrame\n",
      "ZYXW UpdateEstimatesAction not found in DataFrame\n",
      "ZYXW UpdateFuelDataAction\n",
      "ABCD CreateZFWMessageAction\n",
      "ZYXW UpdateLoadTableAction\n",
      "ABCD EstimateStorePaxDataAction\n",
      "ABCD RampFinalAction\n",
      "ZYXW UpdateTransitLoadTableAction\n",
      "ABCD SendFuelOrderAction not found in DataFrame\n",
      "ABCD SendLoadingInstructionAction\n",
      "ABCD SendLoadsheetAction\n",
      "ABCD SetActualBagWeightIndicatorAction\n",
      "ABCD SetCKIPaxDistributionAction not found in DataFrame\n",
      "ABCD StoreAircraftDataAction\n",
      "ABCD StorePaxDataAction\n",
      "ABCD StorePaxDataGuiAction\n",
      "ABCD StoreRegistrationAndConfigurationAc\n",
      "ABCD TdmCreateLoadingInstructionAction not found in DataFrame\n",
      "ABCD TransferCargoAction\n",
      "ABCD TransferCheckinDataAction\n",
      "MNOP CheckinMsgProcessor\n",
      "ABCD UpdateEstimatesAction\n",
      "ABCD UpdateFuelDataAction\n",
      "ABCD UpdateLoadTableAction\n",
      "MNOP CreateLoadingInstructionAction\n",
      "MNOP CreateLoadsheetAction\n",
      "MNOP CreateZFWMessageAction\n",
      "MNOP EstimateStorePaxDataAction\n",
      "MNOP RampFinalAction\n",
      "ABCD UpdateTransitLoadTableAction\n",
      "MNOP SendFuelOrderAction\n",
      "MNOP SendLoadingInstructionAction\n",
      "MNOP SendLoadsheetAction\n",
      "MNOP SetActualBagWeightIndicatorAction not found in DataFrame\n",
      "MNOP SetCKIPaxDistributionAction not found in DataFrame\n",
      "MNOP StoreAircraftDataAction\n",
      "MNOP StorePaxDataAction\n",
      "MNOP StorePaxDataGuiAction\n",
      "MNOP StoreRegistrationAndConfigurationAc\n",
      "MNOP TdmCreateLoadingInstructionAction\n",
      "MNOP TransferCargoAction\n",
      "MNOP TransferCheckinDataAction\n",
      "MNOP UpdateEstimatesAction\n",
      "MNOP UpdateFuelDataAction\n",
      "MNOP UpdateLoadTableAction\n",
      "MNOP UpdateTransitLoadTableAction not found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_AB,\n",
    "            target_file=PARQUET_AB_CONV,\n",
    "            label=\"ABCD\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_MN,\n",
    "            target_file=PARQUET_MN_CONV,\n",
    "            label=\"MNOP\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_ZY,\n",
    "            target_file=PARQUET_ZY_CONV,\n",
    "            label=\"ZYXW\",\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight:\n",
    "    def __init__(self, key, desc=None):\n",
    "        self.key = key\n",
    "        self.description = desc\n",
    "\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "\n",
    "    def get_description(self):\n",
    "        return self.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightCluster:\n",
    "    def __init__(self, name: str, weights: Dict[Weight, str | Tuple[str, ...]]):\n",
    "        self._name = name\n",
    "        self._weights = weights\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self._weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    def __init__(self, name: str, weights: Dict[Weight, str | Tuple[str, ...]]):\n",
    "        self._name = name\n",
    "        self._weights = weights\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    def get_weight_items(\n",
    "        self,\n",
    "    ):\n",
    "        return self._weights.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EZFW = Weight(key=\"EZFW\", desc=\"Estimated Zero Fuel Weight\")\n",
    "AZFW = Weight(key=\"AZFW\", desc=\"Actual Zero Fuel Weight\")\n",
    "\n",
    "ETOW = Weight(key=\"ETOW\", desc=\"Estimated Takeoff Weight\")\n",
    "ATOW = Weight(key=\"ATOW\", desc=\"Actual Takeoff Weight\")\n",
    "\n",
    "ETTL = Weight(key=\"ETTL\", desc=\"Estimated Traffic Load\")\n",
    "ATTL = Weight(key=\"ATTL\", desc=\"Actual Total Traffic Load\")\n",
    "\n",
    "DOW = Weight(key=\"DOW\", desc=\"Dry Operating Weight\")\n",
    "MEW = Weight(key=\"MEW\", desc=\"Manufacturers Empty Weight\")\n",
    "\n",
    "TAOF = Weight(key=\"TAOF\", desc=\"Take Off Fuel\")\n",
    "TRIF = Weight(key=\"TRIF\", desc=\"Trip Fuel\")\n",
    "TAXF = Weight(key=\"TAXF\", desc=\"Taxi Fuel\")\n",
    "\n",
    "ALAW = Weight(key=\"ALAW\", desc=\"Actual Landing Weight\")\n",
    "\n",
    "PAXW = Weight(key=\"PAXW\", desc=\"Passenger Weight\")\n",
    "BAGW = Weight(key=\"BAGW\", desc=\"Baggage Weight\")\n",
    "CARW = Weight(key=\"CARW\", desc=\"Cargo Weight\")\n",
    "MAIW = Weight(key=\"MAIW\", desc=\"Mail Weight\")\n",
    "EICW = Weight(key=\"EICW\", desc=\"Equipment In Compartment Weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADSHEETACTION = WeightCluster(\n",
    "    name=\"LOADSHEETACTION\",\n",
    "    weights={\n",
    "        ATTL: \"TOTAL TRAFFIC LOAD\",\n",
    "        DOW: \"DRY OPERATING WEIGHT\",\n",
    "        AZFW: \"ZERO FUEL WEIGHT ACTUAL\",\n",
    "        TAOF: \"TAKE OFF FUEL\",\n",
    "        ATOW: \"TAKE OFF WEIGHT ACTUAL\",\n",
    "        TRIF: \"TRIP\",\n",
    "        ALAW: \"LANDING WEIGHT ACTUAL\",\n",
    "    },\n",
    ")\n",
    "\n",
    "CALCULATEWEIGHTANDTRIMACTION = WeightCluster(\n",
    "    name=\"CALCULATEWEIGHTANDTRIMACTION\",\n",
    "    weights={\n",
    "        MEW: \"START_WI weight\",\n",
    "        DOW: \"DO_WI weight\",\n",
    "        PAXW: \"PAX_WI weight\",\n",
    "        AZFW: \"AZFW\",\n",
    "        EZFW: \"ESTIMATED_ZFW\",\n",
    "        ATOW: \"ATOW\",\n",
    "        ALAW: \"ALAW\",\n",
    "        ETTL: \"ESTIMATED_TRAFFIC_LOAD\",\n",
    "        ATTL: \"TOTAL_TRAFFIC_LOAD\",\n",
    "    },\n",
    ")\n",
    "\n",
    "CreateZFWMessageAction = WeightCluster(\n",
    "    name=\"CreateZFWMessageAction\",\n",
    "    weights={\n",
    "        DOW: \"dryOperatingWeight\",\n",
    "        AZFW: \"actualZFW\",\n",
    "        CARW: \"cargoWeight\",\n",
    "        BAGW: \"baggageWeight\",\n",
    "        PAXW: \"paxWeight\",\n",
    "        DOW: \"basicWeight\",\n",
    "    },\n",
    ")\n",
    "\n",
    "StoreRegistrationAndConfigurationAc = WeightCluster(\n",
    "    name=\"StoreRegistrationAndConfigurationAc\",\n",
    "    weights={MEW: \"start_weight\", DOW: \"basic_empty_weight\"},\n",
    ")\n",
    "\n",
    "TOTALS = WeightCluster(\n",
    "    name=\"TOTALS\",\n",
    "    weights={\n",
    "        BAGW: \"Total baggage\",\n",
    "        CARW: \"Total cargo\",\n",
    "        MAIW: \"Total mail\",\n",
    "        EICW: \"Total EIC\",\n",
    "    },\n",
    ")\n",
    "\n",
    "UpdateEstimatesAction = WeightCluster(\n",
    "    name=\"UpdateEstimatesAction\",\n",
    "    weights={\n",
    "        PAXW: \"Pax Weight\",\n",
    "        BAGW: \"Bag Weight\",\n",
    "        CARW: \"Cargo\",\n",
    "        MAIW: \"Mail\",\n",
    "        ETTL: \"Traffic Load\",\n",
    "        DOW: \"DOW\",\n",
    "        EZFW: \"EZFW\",\n",
    "    },\n",
    ")\n",
    "UpdateFuelDataAction = WeightCluster(\n",
    "    name=\"UpdateFuelDataAction\",\n",
    "    weights={\n",
    "        TAOF: \"take_off_fuel\",\n",
    "        TRIF: \"trip_fuel\",\n",
    "        TAXF: \"taxi_fuel\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_WEIGHTS = [\n",
    "    # Action(name=\"RampFinalAction\", weights={EZFW: \"EZFW\"}), # EZFW is not a value just a status\n",
    "    Action(\n",
    "        name=\"CalculateWeightAndTrimAction\",\n",
    "        weights=CALCULATEWEIGHTANDTRIMACTION.get_weights(),\n",
    "    ),\n",
    "    Action(name=\"CreateZFWMessageAction\", weights=CreateZFWMessageAction.get_weights()),\n",
    "    Action(name=\"CreateLoadsheetAction\", weights=LOADSHEETACTION.get_weights()),\n",
    "    Action(name=\"SendLoadsheetAction\", weights=LOADSHEETACTION.get_weights()),\n",
    "    Action(\n",
    "        name=\"StoreRegistrationAndConfigurationAc\",\n",
    "        weights=StoreRegistrationAndConfigurationAc.get_weights(),\n",
    "    ),\n",
    "    Action(name=\"TransferCargoAction\", weights=TOTALS.get_weights()),\n",
    "    Action(name=\"UpdateFuelDataAction\", weights=UpdateFuelDataAction.get_weights()),\n",
    "    Action(name=\"UpdateLoadTableAction\", weights=TOTALS.get_weights()),\n",
    "    Action(name=\"UpdateTransitLoadTableAction\", weights=TOTALS.get_weights()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to find the value for a given key\n",
    "def find_value(data: dict | list, key: str):\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            if k == key:\n",
    "                if v is None:\n",
    "                    return None\n",
    "\n",
    "                if isinstance(v, numbers.Number):\n",
    "                    return v\n",
    "                if isinstance(v, str):\n",
    "                    if v.lower() == \"null\":\n",
    "                        return None\n",
    "\n",
    "                    try:\n",
    "                        return eval(v)\n",
    "                    except:\n",
    "                        raise ValueError(\n",
    "                            \"Value not a number string or a number\", key, v\n",
    "                        )\n",
    "\n",
    "                return None\n",
    "            else:\n",
    "                found = find_value(v, key)\n",
    "                if found is not None:\n",
    "                    return found\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            found = find_value(item, key)\n",
    "            if found is not None:\n",
    "                return found\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to apply the recursive search to JSON data\n",
    "def extract_key(json_str: str, key: str):\n",
    "    data = json.loads(json_str)\n",
    "    return find_value(data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(\n",
    "    source_file: Path,\n",
    "    target_file: Path,\n",
    "    label: str | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extract specific data based on predefined action extractors, optionally displaying a progress bar and labels.\n",
    "\n",
    "    This function iterates over a dictionary of action names and their associated extractor functions, applying each\n",
    "    extractor to the relevant entries in the DataFrame. The results are stored in new columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which data will be extracted.\n",
    "            It must contain columns that match the keys in the action_extractors dictionary.\n",
    "        progress_bar (bool, optional): If True, displays a progress bar during the data extraction process.\n",
    "            Useful for visual feedback during long operations. Defaults to False.\n",
    "        label (str | None, optional): An optional label that prefixes the print statements for better traceability during debugging.\n",
    "            If None, only the action name is printed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns containing the extracted data.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        df = pd.read_parquet(source_file)\n",
    "    df = df.replace({None: pd.NA})\n",
    "    for action in ACTION_WEIGHTS:\n",
    "        print(label, action.get_name())\n",
    "        if not f\"data_{action.get_name()}\" in list(df.columns):\n",
    "            continue\n",
    "        for weight, key in action.get_weight_items():\n",
    "\n",
    "            mask = (df.action_name == action.get_name()) & (\n",
    "                ~df[f\"data_{action.get_name()}\"].isna()\n",
    "            )\n",
    "\n",
    "            # Use loc to update the DataFrame directly\n",
    "            df.loc[mask, weight.get_key()] = df.loc[\n",
    "                mask, f\"data_{action.get_name()}\"\n",
    "            ].apply(lambda x: extract_key(x, key))\n",
    "\n",
    "    df.to_parquet(target_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZYXW CalculateWeightAndTrimAction\n",
      "ABCD CalculateWeightAndTrimAction\n",
      "MNOP CalculateWeightAndTrimAction\n",
      "ZYXW CreateZFWMessageAction\n",
      "ZYXW CreateLoadsheetAction\n",
      "ZYXW SendLoadsheetAction\n",
      "ZYXW StoreRegistrationAndConfigurationAc\n",
      "ZYXW TransferCargoAction\n",
      "ZYXW UpdateFuelDataAction\n",
      "ZYXW UpdateLoadTableAction\n",
      "ZYXW UpdateTransitLoadTableAction\n",
      "ABCD CreateZFWMessageAction\n",
      "ABCD CreateLoadsheetAction\n",
      "ABCD SendLoadsheetAction\n",
      "ABCD StoreRegistrationAndConfigurationAc\n",
      "ABCD TransferCargoAction\n",
      "ABCD UpdateFuelDataAction\n",
      "ABCD UpdateLoadTableAction\n",
      "ABCD UpdateTransitLoadTableAction\n",
      "MNOP CreateZFWMessageAction\n",
      "MNOP CreateLoadsheetAction\n",
      "MNOP SendLoadsheetAction\n",
      "MNOP StoreRegistrationAndConfigurationAc\n",
      "MNOP TransferCargoAction\n",
      "MNOP UpdateFuelDataAction\n",
      "MNOP UpdateLoadTableAction\n",
      "MNOP UpdateTransitLoadTableAction\n"
     ]
    }
   ],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            extract_weights,\n",
    "            source_file=PARQUET_AB_CONV,\n",
    "            target_file=PARQUET_AB_WEIGHTS,\n",
    "            label=\"ABCD\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_weights,\n",
    "            source_file=PARQUET_MN_CONV,\n",
    "            target_file=PARQUET_MN_WEIGHTS,\n",
    "            label=\"MNOP\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_weights,\n",
    "            source_file=PARQUET_ZY_CONV,\n",
    "            target_file=PARQUET_ZY_WEIGHTS,\n",
    "            label=\"ZYXW\",\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract flighttable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion zum Extrahieren von Daten aus JSON-Spalten\n",
    "def extract_json_data(row, column, keys):\n",
    "    try:\n",
    "        if pd.notna(row[column]):\n",
    "            data = json.loads(row[column])\n",
    "            for key in keys:\n",
    "                data = data.get(key, None)\n",
    "            return data\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = {\n",
    "    \"estimated_Y\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Y\"]),\n",
    "    \"estimated_Jump\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Jump\"]),\n",
    "    \"estimated_Standby\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Standby\"]),\n",
    "    \"estimated_Male\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Male\"]),\n",
    "    \"estimated_Female\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Female\"]),\n",
    "    \"estimated_Child\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Child\"]),\n",
    "    \"estimated_Infant\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Infant\"]),\n",
    "    \"estimated_Bags\": (\"data_EstimateStorePaxDataAction\", [\"estimated_Bags\"]),\n",
    "    \"aircraft_regTailNbr\": (\"data_CheckinMsgProcessor\", [\"aircraft_regTailNbr\"]),\n",
    "    \"aircraft_Type\": (\"data_CheckinMsgProcessor\", [\"aircraft_Type\"]),\n",
    "    \"aircraft_configuration\": (\"data_CheckinMsgProcessor\", [\"aircraft_configuration\"]),\n",
    "    \"airline\": (\"data_CreateZFWMessageAction\", [\"airline\"]),\n",
    "    \"arrivalStation\": (\"data_CreateZFWMessageAction\", [\"arrivalStation\"]),\n",
    "    # \"departureStation\": (\"data_CreateZFWMessageAction\", [\"departureStation\"]),\n",
    "    \"flightDateLocal\": (\"data_CreateZFWMessageAction\", [\"flightDateLocal\"]),\n",
    "    \"revisionNumber\": (\"data_CreateZFWMessageAction\", [\"revisionNumber\"]),\n",
    "    \"PAX\": (\"data_StorePaxDataAction\", [\"PAX\"]),\n",
    "    \"Y\": (\"data_StorePaxDataAction\", [\"Y\"]),\n",
    "    \"Jump\": (\"data_StorePaxDataAction\", [\"Jump\"]),\n",
    "    \"Standby\": (\"data_StorePaxDataAction\", [\"Standby\"]),\n",
    "    \"Male\": (\"data_StorePaxDataAction\", [\"Male\"]),\n",
    "    \"Female\": (\"data_StorePaxDataAction\", [\"Female\"]),\n",
    "    \"Infant\": (\"data_StorePaxDataAction\", [\"Infant\"]),\n",
    "    \"Bags\": (\"data_StorePaxDataAction\", [\"Bags\"]),\n",
    "    # 'Flight_Number': ('data_CreateLoadingInstructionAction', ['Flight_Number']),\n",
    "    # 'Flight_Date': ('data_CreateLoadingInstructionAction', ['Flight_Date']),\n",
    "    # \"Flight_Route_From\": (\n",
    "    #     \"data_CreateLoadingInstructionAction\",\n",
    "    #     [\"Flight_Route\", \"From\"],\n",
    "    # ),\n",
    "    # \"Flight_Route_To\": (\"data_CreateLoadingInstructionAction\", [\"Flight_Route\", \"To\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flight(\n",
    "    source_file: Path,\n",
    "    target_file: Path,\n",
    "    label: str | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    print(label, \"Extracting flight data\")\n",
    "    if df is None:\n",
    "        df = pd.read_parquet(source_file)\n",
    "        # Neue Spalten erstellen und Daten extrahieren\n",
    "    for new_col, (json_col, json_keys) in new_columns.items():\n",
    "        df[new_col] = df.apply(\n",
    "            lambda row: extract_json_data(row, json_col, json_keys), axis=1\n",
    "        )\n",
    "\n",
    "    existing_columns = set(df.columns)\n",
    "\n",
    "    # Erstellen der Aggregations-Dictionary unter Berücksichtigung der vorhandenen Spalten\n",
    "    agg_dict = {col: \"last\" for col in new_columns.keys() if col in existing_columns}\n",
    "    additional_columns = [\n",
    "        \"airline_code\",\n",
    "        \"flight_number\",\n",
    "        \"flight_suffix\",\n",
    "        \"flight_date\",\n",
    "        \"departure_airport\",\n",
    "    ]\n",
    "    agg_dict.update(\n",
    "        {col: \"last\" for col in additional_columns if col in existing_columns}\n",
    "    )\n",
    "\n",
    "    # flight_suffix-Spalte direkt aus der Parquet-Datei übernehmen\n",
    "    df_agg = df.groupby(\"flightid\").agg(agg_dict).reset_index()\n",
    "    print(label, \"Writing to parquet\")\n",
    "    df_agg.to_parquet(target_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD Extracting flight data\n",
      "MNOP Extracting flight data\n",
      "ZYXW Extracting flight data\n",
      "ZYXW Writing to parquet\n",
      "ABCD Writing to parquet\n",
      "MNOP Writing to parquet\n"
     ]
    }
   ],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            extract_flight,\n",
    "            source_file=PARQUET_AB_CONV,\n",
    "            target_file=PARQUET_AB_FLIGHTTABLE,\n",
    "            label=\"ABCD\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_flight,\n",
    "            source_file=PARQUET_MN_CONV,\n",
    "            target_file=PARQUET_MN_FLIGHTTABLE,\n",
    "            label=\"MNOP\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_flight,\n",
    "            source_file=PARQUET_ZY_CONV,\n",
    "            target_file=PARQUET_ZY_FLIGHTTABLE,\n",
    "            label=\"ZYXW\",\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airportsdata\n",
    "\n",
    "AIRPORTS = airportsdata.load(\"IATA\")  # key is the IATA location code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRPORTS_NOT_IN_AIRPORTSDATA = {\n",
    "    \"SSV\": {\n",
    "        \"lat\": 5.55215,\n",
    "        \"lon\": 120.819,\n",
    "    },\n",
    "    \"JJG\": {\n",
    "        \"lat\": -28.6744444444,\n",
    "        \"lon\": -49.0588888889,\n",
    "    },\n",
    "    \"EEA\": {\n",
    "        \"lat\": -27.634167,\n",
    "        \"lon\": -50.358333,\n",
    "    },\n",
    "    \"SMT\": {\n",
    "        \"lat\": -12.472778,\n",
    "        \"lon\": -55.668889,\n",
    "    },\n",
    "    \"ARX\": {\n",
    "        \"lat\": -4.568611,\n",
    "        \"lon\": -37.804722,\n",
    "    },\n",
    "    \"LHN\": {\n",
    "        \"lat\": -19.355278,\n",
    "        \"lon\": -40.071389,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airportcode_to_coordinates(airportcode: str) -> Tuple[str, str]:\n",
    "    if airportcode in AIRPORTS:\n",
    "        airport = AIRPORTS[airportcode]\n",
    "        return airport[\"lat\"], airport[\"lon\"]\n",
    "    elif airportcode in AIRPORTS_NOT_IN_AIRPORTSDATA:\n",
    "        airport = AIRPORTS_NOT_IN_AIRPORTSDATA[airportcode]\n",
    "        return airport[\"lat\"], airport[\"lon\"]\n",
    "    elif airportcode is not None:\n",
    "        print(f\"Airport code {airportcode} not found in the database\")\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_airport_loc(\n",
    "    source_file: Path,\n",
    "    target_file: Path,\n",
    "    label: str | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    print(label, \"Extracting airport location data\")\n",
    "    if df is None:\n",
    "        df = pd.read_parquet(source_file)\n",
    "\n",
    "    for airport_col in [\"departure_airport\", \"arrivalStation\"]:\n",
    "        # TODO add arrival_airport\n",
    "        df[airport_col + \"_lat\"], df[airport_col + \"_lon\"] = zip(\n",
    "            *df[airport_col].apply(airportcode_to_coordinates)\n",
    "        )\n",
    "\n",
    "    df.to_parquet(target_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCD Extracting airport location data\n",
      "MNOP Extracting airport location data\n",
      "ZYXW Extracting airport location data\n"
     ]
    }
   ],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            extract_airport_loc,\n",
    "            source_file=PARQUET_AB_FLIGHTTABLE,\n",
    "            target_file=PARQUET_AB_FLIGHTTABLE,\n",
    "            label=\"ABCD\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_airport_loc,\n",
    "            source_file=PARQUET_MN_FLIGHTTABLE,\n",
    "            target_file=PARQUET_MN_FLIGHTTABLE,\n",
    "            label=\"MNOP\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_airport_loc,\n",
    "            source_file=PARQUET_ZY_FLIGHTTABLE,\n",
    "            target_file=PARQUET_ZY_FLIGHTTABLE,\n",
    "            label=\"ZYXW\",\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Weight and Flightables and Automationtable from Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voelk\\AppData\\Local\\Temp\\ipykernel_30704\\2637844546.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_weights = pd.concat([ab_w, mn_w, zy_w])\n"
     ]
    }
   ],
   "source": [
    "ab_w = pd.read_parquet(PARQUET_AB_WEIGHTS)\n",
    "mn_w = pd.read_parquet(PARQUET_MN_WEIGHTS)\n",
    "zy_w = pd.read_parquet(PARQUET_ZY_WEIGHTS)\n",
    "\n",
    "df_weights = pd.concat([ab_w, mn_w, zy_w])\n",
    "\n",
    "df_weights.drop(\n",
    "    [\n",
    "        \"header_line\",\n",
    "        \"entry_details\",\n",
    "        \"data_CalculateWeightAndTrimAction\",\n",
    "        \"data_CheckinMsgProcessor\",\n",
    "        \"data_CreateLoadingInstructionAction\",\n",
    "        \"data_CreateLoadsheetAction\",\n",
    "        \"data_CreateZFWMessageAction\",\n",
    "        \"data_EstimateStorePaxDataAction\",\n",
    "        \"data_RampFinalAction\",\n",
    "        \"data_SendLoadingInstructionAction\",\n",
    "        \"data_SendLoadsheetAction\",\n",
    "        \"data_SetActualBagWeightIndicatorAction\",\n",
    "        \"data_StoreAircraftDataAction\",\n",
    "        \"data_StorePaxDataAction\",\n",
    "        \"data_StorePaxDataGuiAction\",\n",
    "        \"data_StoreRegistrationAndConfigurationAc\",\n",
    "        \"data_TransferCargoAction\",\n",
    "        \"data_TransferCheckinDataAction\",\n",
    "        \"data_UpdateEstimatesAction\",\n",
    "        \"data_UpdateFuelDataAction\",\n",
    "        \"data_UpdateLoadTableAction\",\n",
    "        \"data_UpdateTransitLoadTableAction\",\n",
    "        \"data_SendFuelOrderAction\",\n",
    "        \"data_TdmCreateLoadingInstructionAction\",\n",
    "        \"data_SetCKIPaxDistributionAction\",\n",
    "        \"id\",\n",
    "        \"user_name\",\n",
    "        \"action_name\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "df_weights.to_parquet(PARQUET_WEIGHTS, engine=\"pyarrow\", compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_f = pd.read_parquet(PARQUET_AB_FLIGHTTABLE)\n",
    "mn_f = pd.read_parquet(PARQUET_MN_FLIGHTTABLE)\n",
    "zy_f = pd.read_parquet(PARQUET_ZY_FLIGHTTABLE)\n",
    "\n",
    "df_flighttable = pd.concat([ab_f, mn_f, zy_f])\n",
    "df_flighttable.to_parquet(PARQUET_FLIGHTTABLE, engine=\"pyarrow\", compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_a = pd.read_parquet(PARQUET_AB_AUTOMATIONTABLE)\n",
    "mn_a = pd.read_parquet(PARQUET_MN_AUTOMATIONTABLE)\n",
    "zy_a = pd.read_parquet(PARQUET_ZY_AUTOMATIONTABLE)\n",
    "\n",
    "df_flighttable = pd.concat([ab_a, mn_a, zy_a])\n",
    "df_flighttable.to_parquet(\n",
    "    PARQUET_AUTOMATIONTABLE, engine=\"pyarrow\", compression=\"brotli\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide Files as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dict = {\n",
    "    PARQUET_AB_WEIGHTS: CSV_AB_WEIGHTS,\n",
    "    PARQUET_MN_WEIGHTS: CSV_MN_FLIGHTTABLE,\n",
    "    PARQUET_ZY_WEIGHTS: CSV_ZY_WEIGHTS,\n",
    "    PARQUET_WEIGHTS: CSV_WEIGHTS,\n",
    "    PARQUET_AB_FLIGHTTABLE: CSV_AB_FLIGHTTABLE,\n",
    "    PARQUET_MN_FLIGHTTABLE: CSV_MN_FLIGHTTABLE,\n",
    "    PARQUET_ZY_FLIGHTTABLE: CSV_ZY_FLIGHTTABLE,\n",
    "    PARQUET_FLIGHTTABLE: CSV_FLIGHTTABLE,\n",
    "    PARQUET_AB_AUTOMATIONTABLE: CSV_AB_AUTOMATIONTABLE,\n",
    "    PARQUET_MN_AUTOMATIONTABLE: CSV_MN_AUTOMATIONTABLE,\n",
    "    PARQUET_ZY_AUTOMATIONTABLE: CSV_ZY_AUTOMATIONTABLE,\n",
    "    PARQUET_AUTOMATIONTABLE: CSV_AUTOMATIONTABLE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, target in files_dict.items():\n",
    "    pd.read_parquet(source).to_csv(target, index=False, sep=\",\", quotechar='\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
