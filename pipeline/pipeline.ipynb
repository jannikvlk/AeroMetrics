{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import importlib\n",
    "import files\n",
    "from files import *\n",
    "\n",
    "from actions import (\n",
    "    remove_typos,\n",
    "    CalculateWeightAndTrimAction,\n",
    "    CheckinMsgProcessor,\n",
    "    CreateLoadingInstructionAction,\n",
    "    CreateLoadsheetAction,\n",
    "    CreateZFWMessageAction,\n",
    "    EstimateStorePaxDataAction,\n",
    "    RampFinalAction,\n",
    "    SendFuelOrderAction,\n",
    "    SendLoadingInstructionAction,\n",
    "    SendLoadsheetAction,\n",
    "    SetActualBagWeightIndicatorAction,\n",
    "    SetCKIPaxDistributionAction,\n",
    "    StoreAircraftDataAction,\n",
    "    StorePaxDataAction,\n",
    "    StorePaxDataGuiAction,\n",
    "    StoreRegistrationAndConfigurationAc,\n",
    "    TdmCreateLoadingInstructionAction,\n",
    "    TransferCargoAction,\n",
    "    TransferCheckinDataAction,\n",
    "    UpdateEstimatesAction,\n",
    "    UpdateFuelDataAction,\n",
    "    UpdateLoadTableAction,\n",
    "    UpdateTransitLoadTableAction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process:\n",
    "    def __init__(self, func: Callable, **kwargs):\n",
    "        self.func = func\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_func(self) -> Callable:\n",
    "        return self.func\n",
    "\n",
    "    def get_kwargs(self):\n",
    "        return self.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocess(processes: List[Process], workers: int):\n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        futures = []\n",
    "        for process in processes:\n",
    "            futures.append(executor.submit(process.get_func(), **process.get_kwargs())),\n",
    "\n",
    "        for future in futures:\n",
    "            future.result()  # This will re-raise any exceptions that occurred during task execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix broken CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_broken_csv(csv_input_file, csv_output_file):\n",
    "    id_timestamp_pattern = re.compile(r\"^\\d+,\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\")\n",
    "\n",
    "    with open(csv_input_file, \"r\", encoding=\"utf-8\") as infile, open(\n",
    "        csv_output_file, \"w\", encoding=\"utf-8\", newline=\"\"\n",
    "    ) as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        buffer = []\n",
    "        first_line = True\n",
    "\n",
    "        # Read the header from the input file and write it to the output file\n",
    "        header = next(reader)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for line in infile:\n",
    "            line = line.rstrip(\"\\n\")  # Retain trailing newlines by using rstrip('\\n')\n",
    "\n",
    "            # Check if the line matches the pattern for a new entry\n",
    "            if id_timestamp_pattern.match(line):\n",
    "                # If buffer is not empty, process the previous buffered entry\n",
    "                if not first_line:\n",
    "                    combined_line = \"\\n\".join(buffer)\n",
    "                    # Add closing quote if the previous entry was not closed properly\n",
    "                    if combined_line.count('\"') % 2 != 0:\n",
    "                        combined_line += '\"'\n",
    "                    writer.writerow(csv.reader([combined_line]).__next__())\n",
    "\n",
    "                # Start a new buffer with the current line\n",
    "                buffer = [line]\n",
    "                first_line = False\n",
    "            else:\n",
    "                # Continue the buffer\n",
    "                buffer.append(line)\n",
    "\n",
    "        # Handle the last buffer if not empty\n",
    "        if buffer:\n",
    "            combined_line = \"\\n\".join(buffer)\n",
    "            # Add closing quote if the last entry was not closed properly\n",
    "            if combined_line.count('\"') % 2 != 0:\n",
    "                combined_line += '\"'\n",
    "            writer.writerow(csv.reader([combined_line]).__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_FILE_AB,\n",
    "            csv_output_file=CSV_FILE_AB_FIXED,\n",
    "        ),\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_FILE_MN,\n",
    "            csv_output_file=CSV_FILE_MN_FIXED,\n",
    "        ),\n",
    "        Process(\n",
    "            fix_broken_csv,\n",
    "            csv_input_file=CSV_FILE_ZY,\n",
    "            csv_output_file=CSV_FILE_ZY_FIXED,\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV files and convert them to Parquet files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet_cleaning(csv_file: Path, parquet_file: Path) -> pd.DataFrame:\n",
    "\n",
    "    # read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # remove leading and trailing linebreaks and whitespaces\n",
    "    def custom_strip(text):\n",
    "        if isinstance(text, str):\n",
    "            return text.strip(\"\\n\\r\").strip()\n",
    "        return text\n",
    "\n",
    "    df = df.map(custom_strip, na_action=\"ignore\")\n",
    "\n",
    "    # Drop duplicates ignoring the index\n",
    "    df.drop_duplicates(subset=list(df.columns).remove(\"id\"), inplace=True)\n",
    "\n",
    "    # Set the unique identifier for every flight\n",
    "    df[\"flightid\"] = df.apply(\n",
    "        lambda x: f\"{x['airline_code']}_{x['flight_number']}_{x['flight_date']}_{x['departure_airport']}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Convert creation_time to a datetime object\n",
    "    df[\"creation_time\"] = pd.to_datetime(df[\"creation_time\"])\n",
    "\n",
    "    # Write the dataframe to parquet\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_FILE_AB_FIXED, parquet_file=PARQUET_FILE_AB\n",
    "        ),\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_FILE_MN_FIXED, parquet_file=PARQUET_FILE_MN\n",
    "        ),\n",
    "        Process(\n",
    "            csv_to_parquet_cleaning, csv_file=CSV_FILE_ZY_FIXED, parquet_file=PARQUET_FILE_ZY\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Action Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(remove_typos)\n",
    "importlib.reload(CalculateWeightAndTrimAction)\n",
    "importlib.reload(CheckinMsgProcessor)\n",
    "importlib.reload(CreateLoadingInstructionAction)\n",
    "importlib.reload(CreateLoadsheetAction)\n",
    "importlib.reload(CreateZFWMessageAction)\n",
    "importlib.reload(EstimateStorePaxDataAction)\n",
    "importlib.reload(RampFinalAction)\n",
    "importlib.reload(SendFuelOrderAction)\n",
    "importlib.reload(SendLoadingInstructionAction)\n",
    "importlib.reload(SendLoadsheetAction)\n",
    "importlib.reload(SetActualBagWeightIndicatorAction)\n",
    "importlib.reload(SetCKIPaxDistributionAction)\n",
    "importlib.reload(StoreAircraftDataAction)\n",
    "importlib.reload(StorePaxDataAction)\n",
    "importlib.reload(StorePaxDataGuiAction)\n",
    "importlib.reload(StoreRegistrationAndConfigurationAc)\n",
    "importlib.reload(TdmCreateLoadingInstructionAction)\n",
    "importlib.reload(TransferCargoAction)\n",
    "importlib.reload(TransferCheckinDataAction)\n",
    "importlib.reload(UpdateEstimatesAction)\n",
    "importlib.reload(UpdateFuelDataAction)\n",
    "importlib.reload(UpdateLoadTableAction)\n",
    "importlib.reload(UpdateTransitLoadTableAction)\n",
    "\n",
    "action_extractors = {\n",
    "    \"CalculateWeightAndTrimAction\": CalculateWeightAndTrimAction.extract,\n",
    "    \"CheckinMsgProcessor\": CheckinMsgProcessor.extract,\n",
    "    \"CreateLoadingInstructionAction\": CreateLoadingInstructionAction.extract,\n",
    "    \"CreateLoadsheetAction\": CreateLoadsheetAction.extract,\n",
    "    \"CreateZFWMessageAction\": CreateZFWMessageAction.extract,\n",
    "    \"EstimateStorePaxDataAction\": EstimateStorePaxDataAction.extract,\n",
    "    \"RampFinalAction\": RampFinalAction.extract,\n",
    "    \"SendFuelOrderAction\": SendFuelOrderAction.extract,\n",
    "    \"SendLoadingInstructionAction\": SendLoadingInstructionAction.extract,\n",
    "    \"SendLoadsheetAction\": SendLoadsheetAction.extract,\n",
    "    \"SetActualBagWeightIndicatorAction\": SetActualBagWeightIndicatorAction.extract,\n",
    "    \"SetCKIPaxDistributionAction\": SetCKIPaxDistributionAction.extract,\n",
    "    \"StoreAircraftDataAction\": StoreAircraftDataAction.extract,\n",
    "    \"StorePaxDataAction\": StorePaxDataAction.extract,\n",
    "    \"StorePaxDataGuiAction\": StorePaxDataGuiAction.extract,\n",
    "    \"StoreRegistrationAndConfigurationAc\": StoreRegistrationAndConfigurationAc.extract,\n",
    "    \"TdmCreateLoadingInstructionAction\": TdmCreateLoadingInstructionAction.extract,\n",
    "    \"TransferCargoAction\": TransferCargoAction.extract,\n",
    "    \"TransferCheckinDataAction\": TransferCheckinDataAction.extract,\n",
    "    \"UpdateEstimatesAction\": UpdateEstimatesAction.extract,\n",
    "    \"UpdateFuelDataAction\": UpdateFuelDataAction.extract,\n",
    "    \"UpdateLoadTableAction\": UpdateLoadTableAction.extract,\n",
    "    \"UpdateTransitLoadTableAction\": UpdateTransitLoadTableAction.extract,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_data(\n",
    "    source_file: Path,\n",
    "    target_file: Path,\n",
    "    label: str | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extract specific data based on predefined action extractors, optionally displaying a progress bar and labels.\n",
    "\n",
    "    This function iterates over a dictionary of action names and their associated extractor functions, applying each\n",
    "    extractor to the relevant entries in the DataFrame. The results are stored in new columns in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which data will be extracted.\n",
    "            It must contain columns that match the keys in the action_extractors dictionary.\n",
    "        progress_bar (bool, optional): If True, displays a progress bar during the data extraction process.\n",
    "            Useful for visual feedback during long operations. Defaults to False.\n",
    "        label (str | None, optional): An optional label that prefixes the print statements for better traceability during debugging.\n",
    "            If None, only the action name is printed. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns containing the extracted data.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        df = pd.read_parquet(source_file)\n",
    "\n",
    "    for action_name, extractor in action_extractors.items():\n",
    "        if extractor is not None:\n",
    "            if len(df[df.action_name == action_name]) == 0:\n",
    "                print(label, action_name, \"not found in DataFrame\")\n",
    "                continue\n",
    "\n",
    "            if label:\n",
    "                print(label, action_name)\n",
    "            else:\n",
    "                print(action_name)\n",
    "\n",
    "            df[f\"data_{action_name}\"] = df[df.action_name == action_name][\n",
    "                \"entry_details\"\n",
    "            ].apply(extractor)\n",
    "\n",
    "    df.to_parquet(target_file, engine=\"pyarrow\", compression=\"brotli\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZYXW CalculateWeightAndTrimAction\n",
      "ABCD CalculateWeightAndTrimAction\n",
      "MNOP CalculateWeightAndTrimAction\n",
      "ZYXW CheckinMsgProcessor\n",
      "ZYXW CreateLoadingInstructionAction\n",
      "ZYXW CreateLoadsheetAction\n",
      "ZYXW CreateZFWMessageAction\n",
      "ZYXW EstimateStorePaxDataAction\n",
      "ABCD CheckinMsgProcessor\n",
      "ZYXW RampFinalAction\n",
      "ZYXW SendFuelOrderAction\n",
      "ZYXW SendLoadingInstructionAction\n",
      "ZYXW SendLoadsheetAction\n",
      "ZYXW SetActualBagWeightIndicatorAction\n",
      "ZYXW SetCKIPaxDistributionAction\n",
      "ABCD CreateLoadingInstructionAction\n",
      "ZYXW StoreAircraftDataAction\n",
      "ABCD CreateLoadsheetAction\n",
      "ZYXW StorePaxDataAction\n",
      "ABCD CreateZFWMessageAction\n",
      "ABCD EstimateStorePaxDataAction\n",
      "ZYXW StorePaxDataGuiAction\n",
      "ABCD RampFinalAction\n",
      "ZYXWABCD SendFuelOrderAction not found in DataFrame\n",
      " StoreRegistrationAndConfigurationAc\n",
      "ABCD SendLoadingInstructionAction\n",
      "ABCD SendLoadsheetAction\n",
      "ABCD SetActualBagWeightIndicatorAction\n",
      "ZYXW TdmCreateLoadingInstructionAction\n",
      "ABCD SetCKIPaxDistributionAction not found in DataFrame\n",
      "ABCD StoreAircraftDataAction\n",
      "ZYXW TransferCargoAction\n",
      "ZYXW TransferCheckinDataAction not found in DataFrame\n",
      "ZYXW UpdateEstimatesAction not found in DataFrame\n",
      "ABCD StorePaxDataAction\n",
      "ZYXW UpdateFuelDataAction\n",
      "ZYXW UpdateLoadTableAction\n",
      "ZYXW UpdateTransitLoadTableAction\n",
      "ABCD StorePaxDataGuiAction\n",
      "ABCD StoreRegistrationAndConfigurationAc\n",
      "ABCD TdmCreateLoadingInstructionAction not found in DataFrame\n",
      "ABCD TransferCargoAction\n",
      "ABCD TransferCheckinDataAction\n",
      "ABCD UpdateEstimatesAction\n",
      "MNOP CheckinMsgProcessor\n",
      "ABCD UpdateFuelDataAction\n",
      "ABCD UpdateLoadTableAction\n",
      "MNOP CreateLoadingInstructionAction\n",
      "MNOP CreateLoadsheetAction\n",
      "MNOP CreateZFWMessageAction\n",
      "MNOP EstimateStorePaxDataAction\n",
      "ABCD UpdateTransitLoadTableAction\n",
      "MNOP RampFinalAction\n",
      "MNOP SendFuelOrderAction\n",
      "MNOP SendLoadingInstructionAction\n",
      "MNOP SendLoadsheetAction\n",
      "MNOP SetActualBagWeightIndicatorAction not found in DataFrame\n",
      "MNOP SetCKIPaxDistributionAction not found in DataFrame\n",
      "MNOP StoreAircraftDataAction\n",
      "MNOP StorePaxDataAction\n",
      "MNOP StorePaxDataGuiAction\n",
      "MNOP StoreRegistrationAndConfigurationAc\n",
      "MNOP TdmCreateLoadingInstructionAction\n",
      "MNOP TransferCargoAction\n",
      "MNOP TransferCheckinDataAction\n",
      "MNOP UpdateEstimatesAction\n",
      "MNOP UpdateFuelDataAction\n",
      "MNOP UpdateLoadTableAction\n",
      "MNOP UpdateTransitLoadTableAction not found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "multiprocess(\n",
    "    processes=[\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_FILE_AB,\n",
    "            target_file=PARQUET_FILE_AB_CONV,\n",
    "            label=\"ABCD\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_FILE_MN,\n",
    "            target_file=PARQUET_FILE_MN_CONV,\n",
    "            label=\"MNOP\",\n",
    "        ),\n",
    "        Process(\n",
    "            extract_action_data,\n",
    "            source_file=PARQUET_FILE_ZY,\n",
    "            target_file=PARQUET_FILE_ZY_CONV,\n",
    "            label=\"ZYXW\",\n",
    "        ),\n",
    "    ],\n",
    "    workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weight:\n",
    "    def __init__(self, key, description=None):\n",
    "        self.key = key\n",
    "        self.description = description\n",
    "\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "\n",
    "    def get_description(self):\n",
    "        return self.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightCluster:\n",
    "    def __init__(self, name: str, weights: Dict[Weight, str]):\n",
    "        self._name = name\n",
    "        self._weights = weights\n",
    "\n",
    "    def get_weight_cluster(self):\n",
    "        return self._weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    def __init__(self, name: str, weights: Dict[Weight, str]):\n",
    "        self._name = name\n",
    "        self._weights = weights\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    def get_weight_items(\n",
    "        self,\n",
    "    ):\n",
    "        return self._weights.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EZFW = Weight(\"EZFW\", \"Estimated Zero Fuel Weight\")\n",
    "AZFW = Weight(\"AZFW\", \"Actual Zero Fuel Weight\")\n",
    "ETOW = Weight(\"ETOW\", \"Estimated Takeoff Weight\")\n",
    "ATOW = Weight(\"ATOW\", \"Actual Takeoff Weight\")\n",
    "TTL = Weight(\"TTL\", \"Total Traffic Load\")\n",
    "DOW = Weight(\"DOW\", \"Dry Operating Weight\")\n",
    "TOF = Weight(\"TOF\", \"Take Off Fuel\")\n",
    "TF = Weight(\"TF\", \"Trip Fuel\")\n",
    "ALW = Weight(\"ALW\", \"LANDING WEIGHT ACTUAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADSHEETACTION = {\n",
    "    TTL: \"TOTAL TRAFFIC LOAD\",\n",
    "    DOW: \"DRY OPERATING WEIGHT\",\n",
    "    AZFW: \"ZERO FUEL WEIGHT ACTUAL\",\n",
    "    TOF: \"TAKE OFF FUEL\",\n",
    "    ATOW: \"TAKE OFF WEIGHT ACTUAL\",\n",
    "    TF: \"TRIP\",\n",
    "    ALW: \"LANDING WEIGHT ACTUAL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_WEIGHTS = [\n",
    "    # Action(name=\"RampFinalAction\", weights={EZFW: \"EZFW\"}), # EZFW is not a value just a status\n",
    "    Action(name=\"CreateLoadsheetAction\", weights=LOADSHEETACTION),\n",
    "    Action(name=\"SendLoadsheetAction\", weights=LOADSHEETACTION),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to find the value for a given key\n",
    "def find_value(data: dict | list, key: str):\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            if k == key:\n",
    "                if not isinstance(v, numbers.Number):\n",
    "                    if isinstance(v, str) and v.isdigit():\n",
    "                        v = eval(v)\n",
    "                    else:\n",
    "                        raise ValueError(\"Value not a number string or a number\")\n",
    "                if v < 1_000_000:\n",
    "                    return v\n",
    "                return None\n",
    "            else:\n",
    "                found = find_value(v, key)\n",
    "                if found is not None:\n",
    "                    return found\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            found = find_value(item, key)\n",
    "            if found is not None:\n",
    "                return found\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to apply the recursive search to JSON data\n",
    "def extract_key(json_str: str, key: str):\n",
    "    data = json.loads(json_str)\n",
    "    return find_value(data, key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
